---
title: "The interactions of rational, pragmatic agents  \n lead to efficient language structure and use"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Benjamin N. Peloquin} \\ \texttt{bpeloqui@stanford.edu} \\ Department of Psychology \\ Stanford University
    \And {\large \bf Noah D. Goodman} \\ \texttt{ngoodman@stanford.edu} \\ Department of Computer Science \\ Stanford University
    \And {\large \bf Michael C. Frank} \\ \texttt{mcfrank@university.edu} \\ Department of Psychology \\ Stanford University}

abstract: 
    Despite their diversity, languages around the world share a consistent set of properties and distributional regularities. For example, the distribution of word frequencies, the distribution of syntactic dependency lengths, and the presence of ambiguity are all remarkably consistent across languages. We discuss a framework for studying how these system-level properties emerge from local, in-the-moment interactions of rational, pragmatic speakers and listeners. To do so, we derive a novel objective function for measuring the communicative efficiency of linguistic systems in terms of the interactions of speakers and listeners. We examine the behavior of this objective in a series of simulations focusing on the communicative function of ambiguity in language. These simulations suggest that rational pragmatic agents will produce communicatively efficient systems and that interactions between such agents provide a framework for examining efficient properties of language structure and use more broadly.

    
keywords:
    "Communicative efficiency, Rational Speech Act theory, computational modeling, information theory, agent-based simulation"
    
output: cogsci2016::cogsci_paper
final-submission: \cogscifinalcopy
---


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(gridExtra)
library(ggplot2)
library(xtable)
```

# Introduction

Why do languages look the way they do? Zipf [-@Zipf1949a] proposed that distributional properties found in natural language were evidence of speaker-listener effort minimization. In his own words, “we are arguing that people do in fact act with a maximum economy of effort, and that therefore in the process of speaking-listening they will automatically minimize the expenditure of effort.” Evidence for this claim has been largely derived at the level of the lexicon. Zipf argued that the particular relationship between a word’s frequency and its rank, length, and denotation size could be explained as an emergent property of speaker-listener effort minimization. \par

Zipf articulated what is now considered a *functionalist* approach to language science -- analyzing language structure and use in terms of efficiency. Such an approach might re-frame our opening question as follows: how does having property \textit{x} make using language $\ell$ more or less useful for communication? This efficiency-based framing has produced a rich set of theoretical and empirical targets exploring semantic typology [@RegierKempKay2015a], properties such as ambiguity [@Piantadosi2011a] and compositionality [@KirbyGriffithsSmith2014a], and the efficient use of reduction and redundancy in production [@LevyJaeger2007a; @GenzelCharniak2002a].\par

The approaches above typically posit efficiency measures that are motivated by information-theoretic principles, but they typically do not ground out in language use by interacting agents. In this work, we derive a novel objective function from first principles of \textit{rational language use} and show how optimizing this objective can lead to communicatively efficient systems. We also demonstrate that assumptions about interlocutors impact whether language properties are used efficiently. In this way, we integrate questions of language design and language use in a single framework.\par

Functionalist theories commonly frame language efficiency in terms of a fundamental effort-asymmetry underlying everyday communication: what is “hard” for a speaker is likely different than what is “hard” for a listener. Zipf described this as follows: purely from the standpoint of speaker effort, an optimal language $\ell_{speaker}^*$ would tend toward a vocabulary of a single, low-cost word. Given such a language, the full set of potential meanings would be conveyed using only that word, i.e. $\ell_{speaker}^*$ would be fully ambiguous and all possible meanings would need to be disambiguated by a listener. From the standpoint of listener effort, an optimal language $\ell_{listener}^*$ would map all possible meanings to distinct words, removing a listener's need to disambiguate. In this example, speaker effort is related to *production cost* and listener effort to *understanding or disambiguation cost*. Clearly, natural languages fall between the two extremes of $\ell_{speaker}^*$ and $\ell_{listener}^*$. Zipf proposed that the particular lexicon-level properties he observed were a result of optimization based on these competing forces -- the pressure to jointly minimize speaker and listener effort.\par

But how does this optimization take place? The example given by Zipf [-@Zipf1949a] describes local, communicative interactions in terms of a \textit{reference game}. Speakers intend to refer to some object in the world $m$. They choose some utterance $u$ to transmit this intended meaning, $u \rightarrow m$. The listener attempts to reconstruct this intended meaning given the transmitted utterance, $m \rightarrow u$. Other projects have assumed this basic reference game setting [@RegierKempKay2015a; @Piantadosi2011a] and this simplification of the communicative act has proven productive in theoretical [@FerreriCancho2018a], simulation-based [@KirbyGriffithsSmith2014a] and empirical explorations [@HawkinsFrankeSmithGoodman2018a] of efficient language structure and use.\par

Adopting reference games as a basic unit of analysis suggests that optimization may take place at the level of conversation. Importantly, Zipf's conception of speaker and listener effort should be connected to how language is used; in particular, whether interlocutors engage in pragmatic reasoning during conversation. Under a Gricean treatment of pragmatics, speakers and listeners follow a set of conversational maxims in which they cooperate to transfer information [@Grice1975a]. These maxims appear to emerge from efficiency concerns, however (Horn, 1984). We formalize this connection -- showing how system-level efficiencies can emerge from local interaction behavior of pragmatic agents. Our claim is that to understand an "efficient" property of a system it is essential that we consider how that property is *used* efficiently.\par

We provide a case study for this approach, in which functionalist regularities emerge from the dynamics of pragmatic communication. We choose a property of languages that could, in principle, vary freely, but shows strong regularities across languages. The explanandum is why this regularity holds. We examine ambiguity as our property, extending ideas by Piantadosi et al. [-@Piantadosi2011a]. We define a novel measure of efficiency that depends on the interactional behavior of speaker and listener agents. We adopt the reference game as our primary unit of interaction and model language users with the Rational Speech Act (RSA) framework -- a computational model of language use, which is supported by experimental data on interaction. Using these ingredients, we show that the property of interest (ambiguity) is prevalent in languages that optimize our measure of efficiency (Simulation 1). Further, we show how ambiguity is used efficiently during local, in-the-moment interactions (Simulation 2). Put differently, these simulations examine efficiency from two angles -- in the first we vary languages, fixing agents, and search for efficient language designs. In the second we vary agents, fixing language, and examine efficient use. \par

The contributions of this work are twofold -- we derive a novel measure of linguistic efficiency and also show how the reference game framework, in combination with formal models of communication, can be used to connect ideas about system-level efficiencies to in-the-moment language use.\par

# Exploring efficient language design and use in rational pragmatic agents

```{r plot-reference-game, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=2.5, fig.height=2.5, set.cap.width=T, num.cols.cap=1, fig.cap = "An example reference game with associated literal semantics (in our terminology a ``language'')."}
img <- png::readPNG("figs/game1.png")
grid::grid.raster(img)
```

### Reference games
Zipf’s example of optimal speaker- and listener-languages took the form of a reference game. We adopt that formulation here, assuming these communication games as our basic unit of analysis. In this framework, speakers and listeners are aware of a set of objects $M$ (*meanings*) and are knowledgeable about the set of possible signals $U$ (*utterances*) that can be used to refer to a given meaning (see Figure 1). Utterances may have different relative costs, operationalized via a prior over utterances $P(U)$. Similarly, meanings differ in the relative degree to which they need to be talked about, operationalized as a prior over meanings $P(M)$\footnote{The prior over meanings is equivalent to the \textit{need probabilities} assumed in previous work (Regier, Kemp \& Kay (2015)).}. We consider a set of contexts $C$ with an associated prior $P(C)$. Each context $c\in C$ describes a different distribution over meanings e.g. $p(M|C=c_i) \neq p(M|C=c_j)$. Finally, we consider a set of communicative events $e \in E$ where $<u, m, c> = e$ is an utterance-meaning-context triple.\par

### Languages
A language $\ell$ defines the set of semantic mappings between utterances and meanings. For example, Figure 1 contains four utterances $U = \{\text{"blue"}, \text{"green"}, \text{"square"}, \text{"circle"}\} \text{ and three meanings }M = \{\text{green-square}, \text{blue-square}, \text{green-circle}\}$. The boolean matrix describes the literal semantics of the language. We define a language as "ambiguous" if there is some utterance $u \in U$ which can apply to multiple meanings (i.e. $|[[u_i]]| > 1$)\footnote{We use double brackets $[[\dots]]$ to represent denotation.}. In Figure 1 both the words "square" and "green" are ambiguous so we would say that $\ell$ contains ambiguity.

### Speakers and listeners
The Rational Speech Act framework (RSA) is a computational-level theory of pragmatic language use, which has produced good fit to human communication behavior across a range of language phenomena [@FrankGoodman2012a; @GoodmanFrank2016a]. RSA is a formalization of essential Gricean pragmatic principles -- agents reason about one another and their shared context [@Grice1975a]. We adopt RSA as our representational framework to model Gricean (rational and pragmatic) speakers and listeners in the reference game setting (see \href{https://bit.ly/2RBSGcU}{SI}).\par

An RSA *speaker agent* defines a conditional distribution over utterances, mapping from intended meanings $M$ to utterances $U$ using $\ell$ in a given context $c$. That is, a speaker defines $P_{speaker}(u|m, c; \ell)$. We will use $S(u|m, c; \ell)$ as short-hand throughout.  A *listener agent* defines a conditional distribution over meanings, mapping from utterances $U$ to meanings $M$ using $\ell$ in a given context $c$ (i.e. $L(m|u, c;\ell)$). Speakers and listeners can induce joint distributions over utterance-meaning pairs, although, these distributions may differ:
$$P_{speaker}(u, m | c; \ell) = S(u|m, c; \ell)p(m|c)$$
$$P_{listener}(u, m| c; \ell) = L(m|u, c; \ell)p(u|c)$$

# Zipfian objective for linguistic system efficiency

Zipf (1949) proposed that the particular distributional properties found in natural language emerge from competing speaker and listener pressures. We operationalize this objective in equation (1) -- the efficiency of a linguistic system $\ell$ being used by speaker and listener agents $S$ and $L$ is the sum of the expected speaker and listener effort to communicate over all possible communicative events $e \in E$.\par

\begin{equation}
\begin{split}
  \text{Efficiency}(S, L, \ell) = \mathbb{E}_{e \sim P(E)}[\text{speaker effort}] \\+ \mathbb{E}_{e \sim P(E)}[\text{listener effort}]
\end{split}
\end{equation}

We assume that speaker effort is related to the surprisal of an utterance in a particular context\footnote{In the current set of simulations we consider utterance costs as independent from context (i.e.. $p(u|c)p(c)=p(u)p(c)$).} -- intuitively, the number of bits needed to encode the utterance $u$. This particular formalization of speaker-cost is general enough to accommodate a range of cost instantiations, such as production difficulty via articulation effort, cognitive effort related to lexical access, or others [@BennettGoodman2015a].\par

$$\text{speaker effort} = -log_2(p(u|c))$$

We assume listener effort is the semantic surprisal of a meaning given an utterance. This operationalization of listener effort is intuitively related to existing work in sentence processing in which word comprehension difficulty is proportional to surprisal [@Hale2001a; @Levy2008a].

$$\text{listener effort} = -log_2(L(m|u, c; \ell))$$

Importantly, we assume that events $e = <u, m, c>$ are sampled according to the following generative model -- some context occurs in the world with probability $P(C=c)$. Within this context, an object $m$ occurs with probability $p(m|c)$. The speaker attempts to refer to that object by sampling from her conditional distribution $S(u|m, c; \ell)$ (i.e. $e \sim p(c)p(m|c)S(u|m, c; \ell)$). From these ingredients it is possible to derive the following objective between the speaker and listener distributions (see \href{https://bit.ly/2RBSGcU}{SI 2.1} for complete derivation).
\begin{equation}
\begin{split}
  = \mathbb{E}_{c \sim P(C)}[H_{cross}(P_{speaker}, P_{listener} | c; \ell)]\\
\end{split}
\end{equation}
From an information-theoretic perspective this objective is intuitive: $H_{cross}$ denotes the Cross-Entropy (CE), a measure of dissimilarity between two distributions -- the average number of bits required to communicate under one distribution, given that the “true” distribution differs. In our case, we have an expectation over this term -- the expected difference between the distributions assumed by the speaker $P_{speaker}$ and listener $P_{listener}$ given a set of contexts $C$\footnote{Note that in the single context case $|C|=1$ this objective is simply the speaker-listener Cross-Entropy.}. In other words, an "efficient" language $\ell$ minimizes the distance between what speakers and listeners think.

# Simulating the communicative function of ambiguity

The task of understanding language is marked by a frequent need to handle various forms of ambiguity: lexical, syntactic, among others [@WasowPerforsBeaver2005a]. The ubiquity of this property, however, has been argued to provide evidence that languages have not been optimized for communication [@Chomsky2002a].

Piantadosi et al. [-@Piantadosi2011a] argue just the opposite, claiming that ambiguity is an efficient property of any communication system in which *communication is contextualized*. Simply put, it is useful to have a language that re-uses low-cost material (has ambiguity) so long as the cost of disambiguating the material is low. In particular, context (or common ground) can provide useful information for disambiguation.\par

As an example, say we have two objects ($m_1$ and $m_2$), two utterances ($u_1$ and $u_2$), differing in cost, and two languages ($\ell_1$ and $\ell_2$), describing different utterance-meaning mappings. In language $\ell_1$, the low-cost $u_1$ can be used to refer to both $m_1$ and $m_2$ ($[[u_1]]_{\ell_1} = \{m_1, m_2 \}$), but the high-cost $u_2$ cannot be used at all ($[[u_2]]_{\ell_1} = \emptyset$). By contrast, in language $\ell_2$, $u_1$ can only refer to $m_1$ and $u_2$ can only refer to $m_2$ ($[[u_1]]_{\ell_2} = \{m_1\}$ and $[[u_2]]_{\ell_2} = \{m_2 \}$). While it is cheaper for a speaker to use $\ell_1$ (because speaking it is always lower cost), it is more difficult for a listener (because $u_1$ is ambiguous). Crucially, if context is disambiguating then the speaker can use $u_1$ to refer to either $m_1$ or $m_2$ and $\ell_1$ should be preferred to $\ell_2$.\par

In the following simulations we explore two aspects of Piantadosi’s et al.'s claim. In Simulation 1, we examine the efficient language *structure* aspect of their claim, exploring when the optimal linguistic system $\ell^*$ is most likely to contain ambiguous expressions. In Simulation 2, we explore an efficient language *use* aspect of the claim -- under what assumptions will agents use ambiguity efficiently in a conversation?\par

```{r plot-optimal-langs, fig.env = "figure*", fig.pos = "h", fig.width=6, fig.height=2.8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Panel (A) Vertical axis shows the proportion of optimal languages containing ambiguity. Horizontal axis shows the context-size (1-4) in each condition. Optimal language under CE objective (red). Speaker-optimal (blue). Listener-optimal (green). Error bars represent 95 percent confidence intervals. Panel (B), example CE-optimal language (ambiguous) from a four-context simulation. Panel (C), example CE-optimal language (unambiguous) from a single-context simulation."}
img <- png::readPNG("figs/fig1.png")
grid::grid.raster(img)
```

# Simulation 1:  Optimal languages contain ambiguity when context is informative

We show that ambiguity is an efficient property under our CE objective in the reference game setting. We proceed by generating languages with different amounts of contextual support (varying the size of $|C|$). We search the space of languages, examining whether ones which minimize our objective contain ambiguity. If context leads to more efficient communication, then optimal languages should be more likely to be ambiguous as the amount of context increases.\par

## Simulation set-up

We conduct $N=2000$ simulations. For each simulation we enumerate the set of *valid* languages in which $|U|=|M|=4$ ($U$ is our set of utterances and $M$ our set of meanings). Recall that languages are boolean matrices and a language $\ell \in L$ is "valid" so long as each possible meaning $m \in M$ can be referred to by at least one form $u \in U$ (every column of $\ell$ has some non-zero assignment) and each form maps to at least one meaning (every row has some non-zero assignment). For a given simulation, the goal is to find the language $\ell^*$ which minimizes our objective and then check to see if that language contains ambiguity.\par

We define language efficiency as a function of the particular semantic mappings induced by that language, the speaker and listener agents ($S$ and $L$), as well as the utterance ($P(U)$), meaning ($P(M)$), and context priors ($P(C)$). Rather than assume particular structure, for each simulation we generate $P(U) \sim \text{Dir}(1, |U|)$, $P(M|C=c) \sim \text{Dir}(1, |M|)$ (a separate conditional distribution over meanings for each context $c$), and $P(C) \sim \text{Dir}(1, |C|)$, where $\text{Dir}(1, k)$ specifies the uniform Dirichlet distribution over a $k$-dimensional probability vector.\par

```{r plot-optimal-use, fig.env = "figure*", fig.pos = "h", fig.width=6, fig.height=3, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "(A) shows the empirical probability that our speaker used an ambiguous utterance as a function of discourse position. (B) shows speaker effort across the three models. (C) shows the Cross-Entropy objective under our three speaker models. Error bars represent 95 percent confidence intervals."}

img <- png::readPNG("figs/discourse_grid_plot.png")
grid::grid.raster(img)
```

### Context

We want to assess the impact of *context* on the presence of ambiguity in optimal languages. To do so we consider four conditions with $n=500$ simulations each (that is, 500 unique sets of $\{P(U), P(M|C), P(C)\}$. Our first is a \textit{one-context} condition ($|C|=1$) -- only a single distribution over meanings $P(M)$. In our \textit{two-context} condition ($|C| = 2$), we consider efficiency under both $P(M|C=c_1)$ as well as $P(M|C=c_2)$. \textit{Three-} and \textit{four-context} conditions corresponding accordingly.\par

### Baselines

For comparison, we examine properties of optimal languages under two additional objectives. Zipf [-@Zipf1949a] proposed that the speaker-optimal language $\ell_{speaker}^*$ would minimize speaker effort and the listener-optimal language $\ell_{listener}^*$ would minimize listener effort. We define these objectives using the first and second half of equation 1 (see \href{https://bit.ly/2RBSGcU}{SI 2.2.}).\par

## Results and Discussion

In Simulation 1 we explored the degree to which ambiguity is an efficient property of languages when communication is contextualized. Figure 2, panel (A) plots the proportion of optimal languages under each objective as a function of number of contexts. The red line shows that as the number of contexts increases, so does the probability that an optimal language $\ell^*_{cross}$ contains ambiguity (at least one utterance maps to two meanings) under our CE objective. For comparison we also plot the proportion of speaker-optimal $\ell^*_{speaker}$ (blue line) and listener-optimal $\ell^*_{listener}$ (green line) languages that contain ambiguity. In line with Zipf's predictions, if languages are designed only to minimize speaker effort then optimal languages always contain ambiguity. If languages are designed to minimize listener effort then ambiguity is always avoided.\par

While our results indicate that ambiguity is an efficient property of contextualized language use, these simulations assumed that agents had perfect knowledge of the relevant conditional distributions ($P(M|C)$). This assumption may be too strong for describing much of day-to-day communication -- we seldom interact with others with perfect knowledge of the current context (or topic) at the start of a conversation. To explore how ambiguity may be \textit{used} efficiently in our framework, we next examine a case in which the listener has imperfect knowledge of context at the start of the conversation, but may infer it from the discourse history.\par

# Simulation 2: Rational, pragmatic speakers use ambiguity efficiently

In Simulation 1 we showed that efficiency defined in terms of pragmatic agents leads to a preference for languages that contain ambiguity. In Simulation 2 we assume a single fixed language $\ell$, which contains ambiguity, and instead vary the types of agents using $\ell$. We will show that efficient *use* of ambiguity depends on an agent's ability to use context for disambiguation. More generally, Simulation 2 is intended to demonstrate how we can assess both questions of efficient use (current simulation) as well as design (previous simulation) in the same framework.\par

Imagine a scenario in which a reader is beginning a news article. While they may have some knowledge about the article’s topic (perhaps from the title), they may not have complete knowledge of its contents, including the persons or events involved. In this setting, using a low-cost, but ambiguous referring expression (say a pronoun like "he") early may lead to misunderstanding if context is not informative. But, if by a later position enough contextual information has accumulated, it may be efficient to use the ambiguous expression. We pursue this general framework in Simulation 2 -- examining when in a discourse using ambiguity is efficient. We will consider “context” as analogous to a “topic” of conversation. \par

##  Simulation set-up

We consider a single language $\ell$, which contains both ambiguous and unambiguous utterances. We assume ambiguous utterances are lower cost. Crucially, we do not assume that the listener knows the particular topic ($c_{current}$) of the conversation \textit{a priori}. Rather, that the listener has knowledge of the set of possible topics $C = \{c_1, \dots, c_k\}$, but does not know which one is currently being used by the speaker. Formally, this means the listener does not have access to the correct conditional distribution over meanings $P(M|C=c_{current})$ at the start of the discourse.\par 

Over the course of a discourse $D$, the listener tries to infer both the current topic, $c_{current}$, as well as the particular meaning $m$ of a given utterance $u$. That is, we consider agents who can track the history of previous utterances $D$. Importantly, an agent can attempt to infer the current topic of conversation $c_{current}$ using the discourse history $D$.\par

We conduct $N=600$ simulations, generating discourses of length $|D|=30$ utterances, comparing three speaker models ($n=200$ each). We consider a single language $\ell$\footnote{See SI for the matrix notation of this language.} with $|U|=6$ and $|M|=4$ in which two of the utterances are ambiguous and lower cost than the unambiguous utterances. (Note that use of this particular language is not essential -- the results are broadly generalizable to languages that contain ambiguity, but exploring this space is computationally expensive.)\par

## Speaker agents
We vary the degree to which agents can use context for disambiguation. We consider three types of speaker models. Our \textit{Full pragmatics} agent, models a speaker who reasons about her listener and also has complete recall of the set of utterances in the discourse $D$. This speaker believes that the listener may not know the current topic $c_{current}$ at the start of the discourse, but can infer it over the discourse. We compare two baseline models. The first, a \textit{Partial pragmatics} baseline describes a speaker who reasons about a listener, but assumes they have no access to the discourse history. The second, a \textit{No pragmatics} baseline speaker does not consider a listener at all, but produces utterances according to the underlying language semantics ($\ell$) and topic probabilities ($p(M|C=c_{current}$) (see \href{https://bit.ly/2RBSGcU}{SI 3}).\par

## Hypotheses

We are interested in how each speaker-model uses ambiguity over the discourse. A speaker strategy that is mutually efficient for both agents should avoid ambiguity until sufficient contextual information has accumulated. We should expect this to be reflected in our \textit{Full pragmatics} model who reasons about the listener and discourse history. By contrast, a speaker-optimal model who does not consider the listener should greedily use ambiguous utterances (\textit{No pragmatics} model), while a listener-optimal model should avoid ambiguity entirely (\textit{Partial pragmatics} model).\par

## Results and Discussion

Figure 3, panel (A) shows the empirical probability a speaker uses an ambiguous utterance as a function of discourse position. The \textit{No pragmatics} baseline uses ambiguous utterances frequently and at a constant rate over the discourse. The \textit{Partial pragmatics} baseline avoids ambiguous utterances entirely. But, the \textit{Full pragmatics} model avoids ambiguous material only at the start of the discourse, employing it increasingly as the discourse proceeds. Panel (C) tracks our CE objective for each model over the discourse. Note that the objective decreases for all three models, primarily driven by the listeners updating their beliefs about the actual topic ($P(C=c_{current}|D)$). However, the objective declines more quickly under the \textit{Full} and \textit{Partial pragmatics} speakers as listener agents are better able to infer the correct context. Additionally, the difference in CE between the \textit{Full}- and \textit{Partial pragmatics} models at the end of the discourse is driven by the reduction in speaker costs. Panel (B) tracks speaker effort, which remains constant in both \textit{No pragmatics} and \textit{Partial pragmatics} baselines. But, effort declines in the \textit{Full pragmatics} model as speakers increasingly rely on ambiguous material later in the discourse.\par

# General Discussion

How do the competing pressures imposed by speakers and listeners give rise to the distributional regularities found in natural language? Zipf [-@Zipf1949a] proposed that the asymmetry between speaker and listener costs gives rise to a range of properties at the level of the lexicon. We explored the interactions of rational pragmatic agents as a framework for understanding efficient language structure and use. We focused on an argument on the communicative function of ambiguity [@Piantadosi2011a], deriving a novel speaker-listener Cross-Entropy objective for measuring the efficiency of linguistic systems from first principles of efficient language use. In Simulation 1 we showed that optimal languages are more likely to contain ambiguous material when context is informative. In Simulation 2 we showed how rational pragmatic agents use ambiguous material efficiently in conversation.\par

A limitation of the current work is an analysis of exactly how the CE objective compares to existing measures. For example, previous work has described competing speaker-listener pressures in terms of a trade-off of simplicity and informativeness [@KempRegier2012a] or expressivity and compressibility [@SmithTamarizKirby2013a] to explain linguistic regularities. Future work should assess the degree to which we can derive the same properties as previous studies using our current framework. More generally, we hope that this framework can serve as a domain general tool to assess the range of functionalist theories examining efficient language-structure and use.\par

\vspace{1em} \fbox{\parbox[b][][c]{7.3cm}{\centering {SI and simulations: \href{https://bit.ly/2RBSGcU}{\url{https://bit.ly/2RBSGcU}}, \href{https://github.com/benpeloquin7/zipf_principles}{\url{https://github.com/benpeloquin7/zipf_principles}}}}} \vspace{1em}
\noindent



# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
 \noindent
