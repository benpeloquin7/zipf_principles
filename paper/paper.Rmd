---
title: "The interactions of rational pragmatic agents provide a framework for understanding efficient language structure and use"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Author 1} \\ \texttt{bpeloqui@stanford.edu} \\ Department of Psychology \\ Stanford University
    \And {\large \bf Author 2} \\ \texttt{author1@university.edu} \\ Department of Psychology \\ Some University}

abstract: 
    We discuss a framework for studying the distributional properties of linguistic systems as emerging from in-the-moment interactions of speakers and listeners. Our work takes Zipfian notions of lexicon-level efficiency as a starting point, connecting these ideas to Gricean notions of conversational-level efficiency. To do so, we begin by deriving an objective function for measuring the communicative efficiency of linguistic systems and then examining the behavior of this objective in a series of simulations focusing on the communicative function of ambiguity in language.

    
keywords:
    "Communicative efficiency, Rational Speech Act theory, computational modeling, information theory, agent-based simulation"
    
output: cogsci2016::cogsci_paper
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(xtable)
```

# Introduction

Why do natural languages look they way they do? While Zipf (1935) presented his “Principle of Least Effort” as a domain general framework for understanding human behavior, he took language as his central case-study. He proposed that distributional properties found in natural language were evidence of speaker-listener effort minimization. In his own words, “we are arguing that people do in fact act with a maximum economy of effort, and that therefore in the process of speaking-listening they will automatically minimize the expenditure of effort.” Evidence for this claim was largely derived at the level of the lexicon. Zipf argued that the particular relationship between a word’s frequency and its rank, length, and denotation size could be explained as emergent phenomena from speaker-listener effort minimization. \par

Zipf articulated what is now considered a *functionalist* approach to language science -- analyzing language structure and use in terms of efficiency. Such an approach might reframe our opening question as follows -- how does having \textbf{property x} make using language $\ell$ more or less useful for communication? This reframing provides an opportunity to study both language *structure* (as Zipf primarily did) or *use* in terms of efficiency. For example, Regier et al. (201X) showed that languages appear to organize semantic domains (form-meaning mappings) in maximally efficient ways. Likewise, Piantadosi et al. (2012) argued that lexical ambiguity is an efficient property of any communication system when communication is contextualized. We will return to Piantadosi’s argument later in the paper.\par

Zipf’s original work and subsequent functionalist projects describe a varied set of linguistic properties and human behaviors. Common to many is a characterization of a fundamental effort-asymmetry underlying everyday communication. Simply put, what is effortful as a speaker is likely different from what is effortful as a listener. Zipf characterized this as follows -- purely from the standpoint of speaker effort, what Zipf called "Speaker's Economy," an optimal language $\ell_{speaker}^*$ would tend toward a vocabulary of just a single, low-cost word. Given such a language, the full set of potential meanings would be conveyed using only that word, i.e. $\ell_{speaker}^*$ would be fully ambiguous and all possible meanings would need to be disambiguated by a listener. From the standpoint of listener effort, what Zipf called "Auditor's Economy," an optimal language $\ell_{listener}^*$ would bijectively map all possible meanings to distinct words, eliminating a listener's need to disambiguate. Here the asymmetry is operationalized by different costs -- speaker effort is related to *production cost* and listener effort to *understanding or disambiguation cost*. Clearly natural languages fall between the two extremes of $\ell_{speaker}^*$ and $\ell_{listener}^*$. Zipf proposed that the particular lexicon-level properties he observed emerged from the competition of these forces -- the pressure to jointly minimize speaker and listener effort.\par

This formulation begs the question -- at what level of analysis do local, in-the-moment interactions of speakers and listeners lead to optimized structure at the level of the lexicon? The example given by Zipf (1935) appears to describe local interaction in terms of a reference game. Speakers intend to refer to some object in the world $m$. They choose some utterance $u$ to transmit this intended meaning, $u \rightarrow m$. The listener attempts to reconstruct this intended meaning given the transmitted utterance $m \rightarrow u$. Other functionalist projects have also assumed this basic reference game setting (Regier, et al. (201X); Piantadosi et al. (2012); Kirby, Smith & Folds (201X), OTHERS) and this simplification of the communicative act has proven productive in both theoretical (Ferrer-i-cancho, et al.,  201X), simulation-based (iterated learning stuff) and empirical explorations of efficient language structure and use (Some of Robert’s work here).

This move to study efficient language use in terms of reference games has a strong theoretical underpinnings as well. A half century after Zipf, the linguist Lawrence Horn (1984), highlighted the importance of Zipf’s principles for explaining conversation-level phenomena. Horn suggested a direct link between Zipf’s Speaker and Listener economy and, what was at the time, more recent work on conversational pragmatics by Grice (1975). Horn highlighted that the interaction of Zipf’s forces were “largely responsible for generating Grice’s conversational maxims and the schema for pragmatic inference derived therefrom.” Put differently, system-level efficiency we see in languages is deeply related to local-level efficiency during the in-the-moment interactions of rational pragmatic speakers and listeners. \par

In this work, we present a step toward formalizing Horn’s observation -- connecting Zipfian notions of efficient language structure to Gricean notions of rational conversation. To do so minimally requires three basic ingredients -- (1) a language property we’d like to explain (2) a framework for describing in-the-moment interactions of speaker-listeners and (3) some measure of linguistic efficiency. For the current project we focus on the communicative function of ambiguity for our property (1). To model local, conversational interactions (2) we adopt the Rational Speech-act framework. Finally, (3) we derive an objective function for measuring language efficiency in the reference game setting. Given this framework we can ask the question, “how does having \textbf{lexical ambiguity} make using language $\ell$ more or less useful for communication”? This project is meant to demonstrate the ways in which a range of functionalist theories might make use of such a framework -- replacing *lexical ambiguity* with a range of interesting behaviors and properties.\par 

We begin with a high-level introduction to the modelling framework introducing the basic ingredients we will need to represent language as repeated reference games. Following this introduction we derive a simple objective function for measuring the efficiency of linguistic systems in this setting. Subsequently, we move on to two case-studies examining the questions posed above, framing results in terms of our efficiency measure.

# Exploring efficient language- design and use in rational pragmatic agents

## Simulation set-up.

### Reference games
Zipf’s canonical (1935) example of optimal speaker- and listener-languages took the form of a reference game. We adopt that formulation here, assuming the referential communication, similar to those described by Wittgenstein, as our basic unit of analysis. In this setting, speakers and listeners are aware of a set of objects $M$, which will refer to as *meanings* and are knowledgeable about the set of possible signals $U$ (*utterances*) that could be used to refer to a given meaning. Utterances may have different relative costs, operationalized via a prior over utterances $p(u)$. Similarly, meanings differ in the relative degree to which they need to be talked about, operationalized as a prior over meanings $p(m)$. Note that the prior over meanings are analogous to the *need probabilities* assumed in previous work (Regier, CITATION). We consider a set of contexts $C$ which describe different need probability distributions over our set of meanings $p(m|c)$.

### Languages
A language $\ell$ defines the set of semantic mappings between utterance and meanings. For example, in a world with three utterances $U = \{u_1, u_2, u_3\} \text{ and three meanings }M = \{m_1, m_2, m_3\}$ the boolean matrix 

\begin{center}
\begin{tabular}{ c | c c c } 
& $m_1$ & $m_2$ & $m_3$ \\
\hline
$u_1$ & 1 & 1 & 0 \\
$u_2$ & 0 & 1 & 0 \\
$u_3$ & 0 & 0 & 1 \\
\end{tabular}
\end{center}

describes the literal semantics of $\ell$. E.g. the language describes semantic mappings $[\![u_1]\!]\ = \{m_1, m_2\}, [\![u_2]\!]\ = \{m_2\}, [\![u_3]\!]\ = \{m_3\}$.

### Speakers and listeners
We adopt the Rational Speech-act framework (Frank & Goodman, 2012; Goodman & Frank, 2016) to operationalize our rational speaker-listeners. Under this setting, a *speaker agent* defines a conditional distribution over utterances, mapping from intended meanings $M$ to utterances $U$ using a particular semantic mapping given by $\ell$. That is, a speaker defines $P_{speaker}(u|m;\ell)$. We will use $S(u|m;\ell)$ as short-hand throughout.  A *listener agent* defines a conditional distribution over meanings, mapping from utterances $U$ to meanings $M$ using a particular semantic mapping given by $\ell$. We will use $L(m|u; \ell)$ as shorthand. Note that both speakers and listeners can induce joint distributions over the set of all signaling events $E$, although, importantly, these distributions may differ:
$$P_{speaker}(u, m; \ell) = S(u|m; \ell)p(m)$$
$$P_{listener}(u, m; \ell) = L(m|u; \ell)p(u)$$

In general, we would like to consider the efficiency of a system $\ell$ in terms of these joint distributions.

# Zipfian objective for linguistic system efficiency

## Metrics for optimal linguistic systems in the reference game setting

Zipf proposed that the particular distributional properties found in natural language emerge as a result of competing speaker and listener pressures. We operationalize this in equation (1) -- the efficiency of a linguistic system $\ell$ being used by speaker and listener agents $S$ and $L$ is sum of the expected speaker and listener effort to communicate over all possible communicative events.

\begin{equation}
\text{Efficiency}(S, L, \ell) = \mathbb{E}_{e \in E}[\text{speaker effort}] + \\ \mathbb{E}_{e \in E}[\text{listener effort}]
\end{equation}

Let speaker effort be the negative log probability (surprisal) of a particular utterance. Intuitively, the number of bits needed to encode the utterance $u$.

$$\text{speaker effort} = -log_2(p(u))$$

Let listener effort be the negative log probability a listener disambiguates an intended meaning $m$ given an utterance $u$ Intuitively, the number of guesses a listener would need to discover the intended meaning $m$ given an utterance $u$.
$$\text{listener effort} = -log_2(L(m|u; \ell))$$

Rewriting (1) we now have
\begin{equation}
\begin{split}
\text{Efficiency}(S, L, \ell) = \mathbb{E}_{e \in E}[-log_2(p(u))] + \\
\mathbb{E}_{e \in E}[-log_2(L(m|u; \ell))]
\end{split}
\end{equation}
In general, these expectations are each taken over all possible communicative events $e\in E$ weighted by the probability of a particular event $p(e)$. Recall that is the set of all utterance, meaning pairs $<u, m> = e \in E$.

\begin{equation}
 = \sum_{e \in E}p(e)[-log_2(p(u))] + \sum_{e \in E}p(e)[-log_2(L(m|u; \ell))]
\end{equation}

We assume that the particular joint distribution over $u, m$ pairs follows from a simple generative model. First, some meaning is sampled with probability $p(m)$. Our speaker attempts to convey this intended meaning to a speaker by encoding it in the utterance $u$ via the conditional $S(u|m; \ell)$. Combining these terms leads to the *speaker's joint distribution over events* which we can write as $P_{Speaker}(u, m; \ell) = S(u | m; \ell)p(m)$.

\begin{equation}
\begin{split}
  = \sum_{u, m}p_{speaker}(u, m; \ell)[-log_2(p(u))] + \\ 
   \sum_{u, m}p_{speaker}(u, m; \ell)[-log_2(L(m|u; \ell))]
\end{split}
\end{equation}

Simplifying we arrive at (5):
\begin{equation}
\begin{split}
 = \sum_{u, m}P_{speaker}(u, m; \ell)[-log_2(L(m|u; \ell)p(u))]
 \end{split}
\end{equation}

Note that $L(m|u; \ell)p(u)$ is the listener-based joint distribution over all communicative events ($P_{listener}(u, m; \ell)$).
\begin{equation}
  = \sum_{u, m}P_{speaker}(u, m; \ell)[-log_2(P_{listener}(u, m; \ell))]
\end{equation}
This is the simply the cross-entropy between the speaker an listener joint distributions.
\begin{equation}
\begin{split}
  = \mathbb{E}_{P_{speaker}}[-log_2(P_{listener})] \\
  = H_{cross}(P_{speaker}, P_{listener})
\end{split}
\end{equation}
From a mathematical standpoint this objective is intuitive. An optimal linguistic system being used by a speaker and listener agent will induce a particular set of form-meaning mappings that are both *close* between speaker and listener agents and *peaky* in that they assign non-uniform probability mass to the valid form-meaning mappings.\par

In terms of Zipf’s initial example about an optimal speaker or listener language we might consider just the first or second term. Hypothetically, we might expect the optimal speaker language $\ell_{speaker}*$ to minimize:

\begin{equation}
\ell_{speaker}* = argmin_{\ell\in L}\mathbb{E}_{P_{speaker}(u, m; \ell)}(p(u))
\end{equation}

Likewise we might expect the optimal listener language $\ell_{listener}*$ to minimize:

\begin{equation}
\ell_{listener}* = argmin_{\ell\in L}\mathbb{E}_{P_{speaker}(u, m; \ell)}(L(m|u;\ell)
\end{equation}

# Two case-studies on efficient language use and design
We now have a metric for exploring questions of language optimality in the reference game setting (the speaker-listener cross-entropy). In the following sections we examine the behavior of the objective with respect to the communicative function of ambiguity. 

Ambiguity is ubiquitous in natural language. At a minimum, the listener task in everyday communication is marked by the frequent need to handle lexical ambiguity (words often have multiple meanings) as well as syntactic ambiguity (sentences often have multiple parses), in addition to many other instances of ambiguity (Wasow, Perfors & Beaver, 201X). Chomsky (2002) famously claimed that the presence of ambiguity in natural language provides evidence that language has not been optimized for communication, stating “If you want to make sure that we never misunderstand one another, for that purpose language is not well designed, because you have such properties as ambiguity.” Such an analysis is proximal to the Zipfian optimal Listener language, in which the listener is never required to disambiguate a speaker’s utterance.\par

Piantadosi et al, (2012) essentially argue the opposite. They claim that ambiguity is an *efficient* property of any communication system in which *communication is contextualized*. We provide the heart of their argument here, however we refer to Piantados et al. (2012) for more detail:

*In an unambiguous linguistic system, $m_1$ is mapped to $\ell_1 \in L$ and $m_2$ is mapped to $\ell_2 \in L$, with $\ell_1 \neq \ell_2$. Suppose that $\ell_1$ is easier than $\ell_2$... If $\ell_1$ is easier than $\ell_2$, and $m_1$ and $m_2$ are well-disambiguated by context, then we can always create a linguistic system which is easier overall by mapping $m_1$ and $m_2$ both to $\ell_1$. This costs the same in terms of effort every time we communicate $m_1$, but saves effort every time we communicate $m_2$*\par

In words, the Piantadosi argument might be summarised as -- it is useful to have a language that re-uses low-cost material (has ambiguity) so long as the cost of disambiguating the material is low (so long as the context is informative with respect to the disambiguation).

In the following experiments we inspect two aspects of Piantadosi’s claim. In the first, we examine the efficient language *structure* aspect of the question exploring when the optimal linguistic system (under our cross-entropy objective) is most likely to contain ambiguous lexical items. In the second experiment we explore an efficient language *use* aspect of the question -- at what point in a conversation is it useful for a speaker to use ambiguous lexical material?

## Experiment 1:  Optimal languages contain ambiguity when context is informative

The argument outlined by Piantadosi et al. (2012) is clearly compatible with our current reference game setting with just a single addition -- context. The authors argue that mapping both $m_1$ and $m_2$ to $l_1$ is useful when they can disambiguated *in context*. In our case we consider a context $c$ to specify a re-ordering of the referent need probabilities. That is, $p(m|c_1) \neq p(m|c_2)$. In the two context case.

This in turn, leads to an update to our linguistic efficiency objective as we now would like to consider the average speaker-listener effort over all contextualized communicative events. That is,

\begin{equation}
\sum_{c\in C}p(c)\sum_{u, m}S(u|m, c;\ell)p(m|c)-log[L(m|u,c;\ell)p(u)] = \\ \mathbb{E}_{c\sim P(c)[\mathbb{E}_{P_speaker(u, m, c; \ell)}[-log(P_listener(u, m, c; \ell))]}]
\end{equation}

Note that in the case that $|C| =1$, our objective simplifies to our original equation (7). With this update we can compare linguistics systems $L$ while varying the degree to which context contains useful information by varying the size of $|C|$.\par

### Simulation set-up

#### Basic ingredients
We conduct $N=400$ simulations. For each simulation we enumerate the set of *valid* languages in which $|U|=|M|=4$. Note that a language $\ell \in L$ is "valid" so long as each possible meaning in $m \in M$ can be referred to by at least one form $u \in U$ (every column of $\ell$ has some non-zero assignment). For a given simulation the goal is to find the language $\ell^*$ which minimizers our cross-entropy objective.\par

Recall that language efficiency is both a function of the particular semantic mappings induced by that language, the Speaker and Listener agents, as well as the utterance and meaning priors. Therefore, we randomly generate priors of these values such that $p(m) \sim \text{Dir}(1, |M|)$ and $p(u) \sim \text{Dir}(1, |U|)$ where $\text{Dir}(1, k)$ specifies the uniform Dirichlet distribution over a $k$-dimensional probability vector.

#### Context
Given that we’d like to assess the impact of *context* on our objective we consider four conditions with $n=100$ each. Our first is a *single-context* condition ( $|C|=1$) -- there is a only a single context describing $p(m|c_1)$. Our second condition contains two-contexts  ($|C| = 2$) -- we consider efficiency under both $p(m|c_1)$ as well as $p(m|c_2)$. The third and fourth condition correspond accordingly with $|C|=3$ and $|C| = 4$, respectively.

#### Baselines
For comparison, we also examine properties of optimal languages under two  additional objectives. Zipf (1935) proposed that a language optimized for speaker-ease should consist of a single word. We operationalize this using the first half of equation (1).

\begin{equation}
\text{Speaker-only objective} = \mathbb{E}_{u, m\sim P_{speaker}}[\text{speaker effort}] = \sum_{u, m}P_{speaker}(u, m; \ell)[-log(p(u))]
\end{equation}

Zipf also proposed that the optimal listener language should bijectively map all words to unique meanings. We operationalize this using the second half of equation (1).
\begin{equation}
\text{Listener-only objective} = \mathbb{E}_{u, m\sim P_{speaker}}[\text{listener effort}] = \sum_{u, m}P_{speaker}(u, m; \ell)[-log(L(m|u; \ell)]
\end{equation}

#### Hypotheses
This leads to the following set of hypotheses: (1) The probability that an optimal language contains ambiguity under our Cross-Entropy objective should increase with the number of contexts (as $|C|\rightarrow\inf$). (2) The optimal speaker language under our Speaker-only objective should always map all meanings to the single, lowest cost utterance. (3) The optimal listener language should never contain ambiguous material.

### Results
Figure 1. plots the proportion of optimal languages under $H_{cross}(P_{Speaker}, P_{Listener})$ for each condition. We find that as the number of contexts increases, so does the probability that optimal language $\ell*$ contains ambiguity. For comparison we also include the optimal language under an objective that only considers speaker or listener effort. In line, with Zipf's predictions, if languages are designed only to minimize speaker effort then optimal languages will assign all meanings to a single, low-cost utterance. Likewise, if languages are designed only to minimize speaker listener effort then ambiguity should always be avoided.\par


Piantadosi et al. (2012) framed their theory in terms of conditional entropy. That is, $H(X|C) < H(X)$ when $C$ provides information about $X$. Put differently, when $I(X, C)$ is non-zero. In our setting this would indicate that as the amount of contextual information increases, the difference between the conditional and unconditional measures of information should increase. That is, $H_{cross}(P_{Speaker}, P_{Listener}|C_1) - H_{cross}(P_{Speaker}, P_{Listener}) < H_{cross}(P_{Speaker}, P_{Listener}|C_2) - H_{cross}(P_{Speaker}, P_{Listener})$ when $C_1$ contains more information than $C_2$. We can consider this very metric in our conditions. Figure 2 plots $H_{cross}(P_{Speaker}, P_{Listener}|C_1) - H_{cross}(P_{Speaker}, P_{Listener})$ in each of our conditions. As the number of contexts increases, the difference in efficiency when context is disambiguating increaess as well.\par

### Summary
Piantadosi et al. (2012) argued that it is useful to re-use low-cost linguistic forms for multiple meanings when they can be disambiguated in context. Using our speaker-listener cross-entropy measure of efficiency we showed that optimal langauges are more likely to have ambiguous items when context is informative. Further, we showed that the impact of being able to disambiguate langauge (having access to $p(m|c_i)$) is increasingly efficienct as the amount of common-ground (context) increases.\par

## Experiment 2: Rational-pragmatic speakers use ambiguity efficiently
Our first experiment made a fairly direct test of the communicative function of ambiguity proposed by Piantadosi et al. (2012). Sampling a set of need probabilities and utterance costs we explored the space of possible languages, examining the properties of the language $\ell*$ which minimized our objective. Results indicated that ambiguity is an efficient property when context is informative. This experiment, however, assumed that our speaker and listener agents could disambiguate items context. That is, in our four conditions both agents had access to these conditional distributions $p(m|c_1), \dots, p(m|c_4)$. More often than not in day-to-day language use, speakers and listeners may not have perfect knowledge of the particular set of need probabilities $p(m)$ being used. Put differently, if ambiguity is only efficient when it can be disambiguated in context, speakers should avoid using ambiguous items if they know their listener may not be able to disambiguate the item.\par

In experiment two we examine speaker behavior in a scenario in which the listener does not know the exact set of need probabilites a priori. That is, the listener has uncertainty over $p(m)$. Over the course of a discourse $D$ the listener tries to infer the context along with the particular intended meaning of a given utterance. That is, we consider a listener model $L(c, m|u;D)$ where $c$ is the particular context (or *topic*) being discussed and $D$ is the set of previous utterances the speaker has made. Likewise we consider a speaker model $S(u|m, c, D)$ who chooses an utterance based on an intended meaning $m$, the particular context of conversation $c$, while also considering the history of their utterance $D$. If speakers are behaving efficiently they should only use ambiguous items when they can be disambiguated in context. That is, if the listener agents is able to correctly infer the topic of conversation as the conversation progresses $D\rightarrow\inf$ then the speaker should be more likely to use ambiguous items later in discourse.

### Simulation set-up \newline

$\ell = \text{current language known to both speaker and listener}$\par
$D = \text{History of previous utterances by speaker}$\par
$S(u|m; \ell) = \text{S1 rsa speaker}$\par
$L(m|u; \ell) = \text{L0 rsa listener}$\par
$P(u) = \text{utterance costs in which } p(u_1) < p(u_2) < p(u_3) < p(u_4)$\par
$c = \text{current topic, which specifies need probabilities}$\par
$P(m|c) = \text{set of need probabilites specified by } c$\par

### Results

### Summary

# Conclusion

# Acknowledgements

Place acknowledgments (including funding information) in a section at
the end of the paper.

# References 

```{r fig1, fig.env="figure", fig.pos = "H", fig.align = "center", fig.width=4, fig.height=4, fig.cap = "Optimal languages are more likely to contain ambiguous items as amount of contextual information increases. Vertical axis shows the proportion of optimal languages that contain ambiguity. Horizontal axis shows the number of contexts in each condition (1-4). Red-line represents the optimal langauge under our Zipfian cross-entropy objective while the blue and red lines show optimal languages under speaker- and listener-only consideration."}
img <- png::readPNG("figs/fig1.png")
grid::grid.raster(img)
```

```{r fig2, fig.env="figure", fig.pos = "H", fig.align = "center", fig.width=2.5, fig.height=3, fig.cap = "The gains in efficinecy increase as the amount of contextual information increases. Vertical axis shows the difference in cross-entropy for when context is informative. Horizontal axis shows each of the four conditions. Note that the difference for condition 1 is zero as thered is only a single context." }
img <- png::readPNG("figs/fig2.png")
grid::grid.raster(img)
```

```{r fig3, fig.env="figure", fig.pos = "H", fig.align = "center", fig.width=2.5, fig.height=3, fig.cap = "R plot" }
img <- png::readPNG("figs/fig3.png")
grid::grid.raster(img)
```

```{r fig4, fig.env="figure", fig.pos = "H", fig.align = "center", fig.width=2.5, fig.height=3, fig.cap = "R plot" }
img <- png::readPNG("figs/fig4.png")
grid::grid.raster(img)
```


```{r fig5, fig.env="figure", fig.pos = "H", fig.align = "center", fig.width=2.5, fig.height=3, fig.cap = "R plot" }
img <- png::readPNG("figs/fig5.png")
grid::grid.raster(img)
```


```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
