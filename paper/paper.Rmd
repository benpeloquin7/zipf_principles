---
title: "The interactions of rational, pragmatic agents  \n lead to efficient language structure and use"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Benjamin N. Peloquin} \\ \texttt{bpeloqui@stanford.edu} \\ Department of Psychology \\ Stanford University
    \And {\large \bf Noah D. Goodman} \\ \texttt{ngoodman@stanford.edu} \\ Department of Computer Science \\ Stanford University
    \And {\large \bf Michael C. Frank} \\ \texttt{mcfrank@university.edu} \\ Department of Psychology \\ Stanford University}

abstract: 
    Languages display a diverse set of distributional regularities such as the relation between a word's frequency and rank in a corpus, the distribution of dependency lengths, or the presence of lexical properties such as ambiguity. We discuss a framework for studying how these properties emerge from in-the-moment interactions of rational, pragmatic speakers and listeners. Our work takes notions of lexicon-level efficiency as a starting point, connecting these ideas to notions of conversational-level efficiency. To do so, we derive an objective function for measuring the communicative efficiency of linguistic systems and then examining the behavior of this objective in a series of simulations focusing on the communicative function of ambiguity in language. These simulations suggest that rational pragmatic agents will produce communicatively efficient systems and that interactions between such agents provide a framework for examining efficient properties of language more broadly.

    
keywords:
    "Communicative efficiency, Rational Speech Act theory, computational modeling, information theory, agent-based simulation"
    
output: cogsci2016::cogsci_paper
---


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(gridExtra)
library(ggplot2)
library(xtable)
```

# Introduction

Why do languages look the way they do? Zipf [-@Zipf1949a] proposed that distributional properties found in natural language were evidence of speaker-listener effort minimization. In his own words, “we are arguing that people do in fact act with a maximum economy of effort, and that therefore in the process of speaking-listening they will automatically minimize the expenditure of effort.” Evidence for this claim has been largely derived at the level of the lexicon. Zipf argued that the particular relationship between a word’s frequency and its rank, length, and denotation size could be explained as an emergent property of speaker-listener effort minimization. \par

Zipf articulated what is now considered a *functionalist* approach to language science -- analyzing language structure and use in terms of efficiency. Such an approach might reframe our opening question as follows -- how does having \textbf{property x} make using language $\ell$ more or less useful for communication? This reframing provides an opportunity to study both language *structure* (as Zipf primarily did) or *use* in terms of efficiency. For example, Regier et al. [-@RegierKempKay2015a] showed that languages appear to organize semantic domains (form-meaning mappings) in maximally efficient ways. Likewise, Piantadosi et al. [-@Piantadosi2011a] argued that lexical ambiguity is an efficient property of any communication system when communication is contextualized.\par

Zipf’s original work and subsequent functionalist projects describe a varied set of linguistic properties and human behaviors. Common to many is a characterization of a fundamental effort-asymmetry underlying everyday communication. Simply put, what is “hard” for a speaker is likely different from what is “hard” for a listener. Zipf characterized this as follows -- purely from the standpoint of speaker effort, an optimal language $\ell_{speaker}^*$ would tend toward a vocabulary of just a single, low-cost word. Given such a language, the full set of potential meanings would be conveyed using only that word, i.e. $\ell_{speaker}^*$ would be fully ambiguous and all possible meanings would need to be disambiguated by a listener. From the standpoint of listener effort, an optimal language $\ell_{listener}^*$ would map all possible meanings to distinct words, removing a listener's need to disambiguate. In this example, speaker effort is related to *production cost* and listener effort to *understanding or disambiguation cost*. Clearly natural languages fall between the two extremes of $\ell_{speaker}^*$ and $\ell_{listener}^*$. Zipf proposed that the particular lexicon-level properties he observed were a result of these competing forces -- the pressure to jointly minimize speaker and listener effort.\par

But how does such optimization take place? The example given by Zipf [-@Zipf1949a], describes local, communicative interactions in terms of a \textit{reference game}. Speakers intend to refer to some object in the world $m$. They choose some utterance $u$ to transmit this intended meaning, $u \rightarrow m$. The listener attempts to reconstruct this intended meaning given the transmitted utterance, $m \rightarrow u$. Other functionalist projects have assumed this basic reference game setting [@RegierKempKay2015a; @Piantadosi2011a] and this simplification of the communicative act has proven productive in theoretical [@FerreriCancho2018a], simulation-based [@KirbyGriffithsSmith2014a] and empirical explorations [@HawkinsFrankeSmithGoodman2018a] of efficient language structure and use.\par

Zipf's conception of speaker and listener effort may be connected to speakers' pragmatic reasoning in the moment. Under a Gricean treatment of pragmatics, speakers and listeners are assumed to follow a set of conversational maxims in which they cooperate to transfer information (Grice, 1975). These maxims appear to emerge from efficiency concerns, however (Horn, 1984). A primary target of the current work is to formalize this connection, by providing a framework for deriving system-level efficiencies from local, interaction behavior. Our claim is that to understand an "efficient" property of a system we need to consider *how* that property is *used* efficiently. Additionally, any quantitative description of "efficiency" should be a function of both the system and users.\par

In the current work we provide a case-study for the kind of framing presented above. We choose a property of languages that could, in principle, vary freely, but shows strong regularities across languages. The explanadum is why this regularity holds. We examine lexical ambiguity as our property, extending ideas by Piantadosi et al. [-@Piantadosi2011a]. We define a novel measure of efficiency that depends on the interactional behavior of interlocutors. For our model of speakers and listeners we adopt the Rational Speech Act (RSA) framework, which is nicely attested in experimental data on pragmatic interaction. With these basic ingredients we have a measure of efficiency given language and speaker-listener agents. Finally, we show that the property of interest is prevalent in languages that optimize this measure of efficiency and also how this property is used efficiently during local interaction. The primary contribution of this work is to show how the reference game frameowrk, in combination with formal models of communication, can be used to connect ideas about system-level efficiencies to in-the-moment language use.\par

# Exploring efficient language design and use in rational pragmatic agents

```{r plot-reference-game, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=2.5, fig.height=2.5, set.cap.width=T, num.cols.cap=1, fig.cap = "An example reference game with associated literal semantics (in our terminology a ``language'')."}
img <- png::readPNG("figs/game1.png")
grid::grid.raster(img)
```

### Reference games
Zipf’s example of optimal speaker- and listener-languages took the form of a reference game. We adopt that formulation here, assuming these communication games as our basic unit of analysis. In this setting, speakers and listeners are aware of a set of objects $M$, which we will refer to as *meanings* and are knowledgeable about the set of possible signals $U$ (*utterances*) that can be used to refer to a given meaning (see Figure 1). Utterances may have different relative costs, operationalized via a prior over utterances $P(U)$. Similarly, meanings differ in the relative degree to which they need to be talked about, operationalized as a prior over meanings $P(M)$\footnote{The prior over meanings are analogous to the \textit{need probabilities} assumed in previous work Regier, Kemp \& Kay (2015).}. We consider a set of contexts $C$ with an associated prior $P(C)$. Contexts encode different meaning priors, formalized as separate conditional distributions over meanings e.g. $p(M|C=c_i) \neq p(M|C=c_j)$. Finally, we consider a set of communicative events $e \in E$ where $<u, m> = e$ is a tuple of utterance, meaning pairs. Note that in the case of single context $|C|=1$ we simply have a prior over meanings $p(M)$, a simplification we will use in introducing our objective function.\par

### Languages
A language $\ell$ defines the set of semantic mappings between utterance and meanings. For example, Figure 1 contains four utterances $U = \{\text{blue}, \text{green}, \text{square}, \text{circle}\} \text{ and three meanings }M = \{\text{green-square}, \text{blue-square}, \text{green-circle}\}$. The boolean matrix describes the literal semantics of the language $\ell$. Note that will consider language to "contain ambiguous items" if there is at least one utterance $u \in U$ which can apply to multiple meanings (i.e. $|[[u_i]]| > 1$)\footnote{We use double brackets $[[\dots]]$ to represent denotation}. For example, in Figure 1 both the words "blue" and "green" are ambigous so we would say that $\ell$ contains ambiguity.

### Speakers and listeners
The Rational Speech-act framework (RSA) is computational-level theory of pragmatic language use. RSA can be understood as a formalization of essential Gricean pragmatic principles -- agents reason about one another and their shared context. For this reason, we adopt RSA as our representational framework to operationalize Gricean (rational and pragmatic) speaker-listeners [@Grice1975a]. We refer the reader to Section 1 of our supplementary materials for a more detailed description of basic RSA speaker-listener definitions, and to Goodman & Frank [-@GoodmanFrank2016a] for an overview of its appliations.\par

An RSA *speaker agent* defines a conditional distribution over utterances, mapping from intended meanings $M$ to utterances $U$ using $\ell$ in a given context $c$. That is, a speaker defines $P_{speaker}(u|m; \ell)$. We will use $S(u|m; \ell)$ as short-hand throughout.  A *listener agent* defines a conditional distribution over meanings, mapping from utterances $U$ to meanings $M$ using $\ell$ in a given context $c$. We will use $L(m|u; \ell)$ as shorthand. Note that both speakers and listeners can induce joint distributions over the set of all events $E$, although, importantly, these distributions may differ:
$$P_{speaker}(u, m; \ell) = S(u|m; \ell)p(m)$$
$$P_{listener}(u, m; \ell) = L(m|u; \ell)p(u)$$

# Zipfian objective for linguistic system efficiency

Zipf (1949) proposed that the particular distributional properties found in natural language emerge from competing speaker and listener pressures. We operationalize this objective in equation (1) -- the efficiency of a linguistic system $\ell$ being used by speaker and listener agents $S$ and $L$ is the sum of the expected speaker and listener effort to communicate over all possible communicative events $E$. Note that to simplify the introduction of this objective we assume there is just a single context ($|C|=1$). In this case $p(C=c)=1$ and there is only distribution over meanings ($p(m|c) = p(m)$). We provide a more detailed description of this derivation in the supplementary materials, both with and without context $C$.\par

\begin{equation}
\begin{split}
  \text{Efficiency}(S, L, \ell) = \mathbb{E}_{e \sim P(E)}[\text{speaker effort}] \\+ \mathbb{E}_{e \sim P(E)}[\text{listener effort}]
\end{split}
\end{equation}

We assume that speaker effort is the negative log probability of an utterance (surprisal) -- intuitively, the number of bits needed to encode the utterance $u$. This particular formalization of speaker-cost is general enough to accommodate a range of instantiations that might in theory be related to production difficult via articulation effort, cognitive effort related to lexical access, etc [@BennettGoodman2015a].\par

$$\text{speaker effort} = -log_2(p(u))$$

We assume listener effort is the negative log probability of the listener's conditional $-log_2(L(m|u))$. This operationalization of listener effort is intuitively related to existing work in sentence processing in which word difficulty during comprehension is proportional to surprisal [@Hale2001a; @Levy2008a].

$$\text{listener effort} = -log_2(L(m|u; \ell))$$

Importantly, we assume that events $e = <u, m>$ are sampled according the to following generative model -- some object occurs in the world with probability $p(M=m)$, the speaker attempts to refer to that object by sampling from her conditional distribution $S(u|m)$ (i.e. $e \sim p(m)S(u|m)$). From the ingredients highlighted above, it is possible to derive the following objective between the speaker and listener joint distributions (see SI 2.2 for a complete derivation).

\begin{equation}
\begin{split}
  = -\mathbb{E}_{P_{speaker}}[log_2(P_{listener})] \\
  = H_{cross}(P_{speaker}, P_{listener}; \ell)
\end{split}
\end{equation}
From an information-theoretic perspective this objective is intuitive: cross-entropy gives us a measure of dissimilarity between two distributions -- the average number of bits required to communicate under one distribution, given that the “true” distribution differs. In our case, this is the difference between the joint distribution assumed by the speaker $P_{speaker}$ and listener $P_{listener}$. In other words, an "efficient" language $\ell$ minimizes the distance between what speakers and listeners think.

# Simulating the communicative function of ambiguity

The task of understanding language is marked by a frequent need to handle various forms of ambiguity; lexical, syntactic, among others [@WasowPerforsBeaver2005a]. The ubiquity of this property, however, has been argued to provide evidence that langauges are not been optimized for communication\footnote{Chomsky (2002) famously claimed "If you want to make sure that we never misunderstand one another, for that purpose language is not well designed, because you have such properties as ambiguity." Note that this analysis is analogous to the Zipfian optimal Listener language $\ell_{listener}^*$ we described earlier and define in terms of equation 2 in SI 2.2 .} [@Chomsky2002a].

Piantadosi et al. [-@Piantadosi2011a] argue just the opposite, claiming that ambiguity is an *efficient* property of any communication system in which *communication is contextualized*. Simply put, it is useful to have a language that re-uses low-cost material (has ambiguity) so long as the cost of disambiguating the material is low. In particular, context (or common ground) can provide useful information for disambiguation.\par

We provide a toy example of their argument here. Say we have two objects in the world $m_1$ and $m_2$, and two languages $\ell_1$ and $\ell_2$. In language $\ell_1$, the low-cost utterance $u_1$ can be used to refer to both $m_1$ and $m_2$ (i.e. $[[u_1]]_{\ell_1} = \{m_1, m_2 \}$ and $[[u_2]]_{\ell_1} = \emptyset$). With language $\ell_2$, however, the low cost utterance $u_1$ can only refer to $m_1$ and a higher-cost utterance $u_2$ can refer to $m_2$ (i.e. $[[u_1]]_{\ell_2} = \{m_1\}$ and $[[u_2]]_{\ell_2} = \{m_2 \}$). While it is cheaper for a speaker to use $\ell_1$ (because she can always use a low-cost utterance), it is more difficult for a listener (because $u_1$ is ambiguous). If context isn't disambiguating then we might prefer $\ell_2$ to $\ell_1$. But, if context is disambiguating then the speaker can use $u_1$ to refer to either $m_1$ or $m_2$ and $\ell_1$ should be preferred.\par

In the following experiments we explore two aspects of Piantadosi’s claim. First, we examine the efficient language *structure* aspect of their claim, exploring when the optimal linguistic system $\ell^*$ is most likely to contain ambiguous lexical items. In the second experiment, we explore an efficient language *use* aspect of the claim -- at what point in a conversation is it useful for a speaker to use ambiguous lexical material?\par

```{r plot-optimal-langs, fig.env = "figure*", fig.pos = "h", fig.width=8, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Optimal languages are more likely to contain ambiguous items as the amount of contextual information increases. Vertical axis shows the proportion of optimal languages that contain ambiguity. Horizontal axis shows the number of contexts in each condition (1-4). Red-line represents the optimal language under our Zipfian cross-entropy objective while the blue and red lines show optimal languages under speaker- and listener-only objectives. Error bars represent 95% confidence intervals."}
img <- png::readPNG("figs/fig1.png")
grid::grid.raster(img)
```

# Simulation 1:  Optimal languages contain ambiguity when context is informative

We adopt the framework above, and (following Piantadosi et al. 2011), add \textit{context} ($C$). The authors argue that mapping two meanings $m_1$ and $m_2$ to a single utterance $u_1$ is useful when they can be disambiguated *in context*. In our case we consider a context $c_i \in C$ to specify a permutation of the meaning probabilities. That is, $p(m|c_1) \neq p(m|c_2)$, when there are two contexts $|C| = \{c_1, c_2\}$.This in turn, leads to an update to our linguistic efficiency objective as we now would like to consider the average speaker-listener effort over all contextualized communicative events (see section 3 SI).\par

We proceed by generating languages with different amounts of contextual support (varying the size of $|C|$). We search the space of languages, asessing if the ones which minimize our objective contain ambiguity. If context leads to more efficient commnication, then optimal languages should be more likley to be ambiguous as the amount of context increases.\par

## Simulation set-up

We conduct $N=2000$ simulations. For each simulation we enumerate the set of *valid* languages in which $|U|=|M|=4$ (recall that $U$ is our set of utterances and $M$ our set of meanings). Note that a language $\ell \in L$ is "valid" so long as each possible meaning in $m \in M$ can be referred to by at least one form $u \in U$ (every column of $\ell$ has some non-zero assignment) and each form maps to at least one meaning (every column has some non-zero assignment)\footnote{For the current set of simulations we consider languages in which there are four or five true values -- in a "four" language ambiguity is not possible, but in a "five" language there are ambiguous mappings.}. For a given simulation the goal is to find the language $\ell^*$ which minimizes our cross-entropy objective and then check to see if that language contains ambiguity.\par

Recall that language efficiency is both a function of the particular semantic mappings induced by that language, the speaker and listener agents ($S$ and $L$), as well as the utterance ($P(U)$), meaning ($P(M)$), and context priors ($P(C)$). Rather than assume particular structure for our utterance, meaning, and context prior distributions, for each simulation we generate $P(U) \sim \text{Dir}(1, |U|)$, $P(M|C=c) \sim \text{Dir}(1, |M|)$ (a separete conditional distribution over meanings for each context $c$), and $P(C) \sim \text{Dir}(1, |C|)$ where $\text{Dir}(1, k)$ specifies the uniform Dirichlet distribution over a $k$-dimensional probability vector.\par

### Context

Following the argument given by Piantadosi et al. [-@Piantadosi2011a], we want to assess the impact of *context* on our objective. To do so we consider four conditions with $n=500$ simulations each (that is, 500 unique sets of $\{P(U), P(M|C), P(C)\}$. Our first is a *single-context* condition ($|C|=1$) -- there is a only a single context describing $P(M)$. Our second condition contains two-contexts  ($|C| = 2$) -- we consider efficiency under both $P(M|C=c_1)$ as well as $P(M|C=c_2)$. The third and fourth condition correspond accordingly with $|C|=3$ and $|C| = 4$, respectively.\par

### Baselines

For comparison, we also examine properties of optimal languages under two additional objectives. Zipf [-@Zipf1949a] proposed that the optimal speaker language $\ell_{speaker}^*$ would only optimize speaker effort and the optimal listener language $\ell_{listener}^*$ would only optimize listener effort. We define these objectives using the first and second half of equation 1 (see SI section 2.2. for more detail).\par

## Results and Discussion

Figure 1. plots the proportion of optimal languages under each objective, as a function of context condition. The red line shows that as the number of contexts increases, so does the probability that the optimal language $\ell^*_{cross}$ under our speaker-listener cross-entropy objective contains ambiguity. We also plot the proportion of optimal speaker-only $\ell^*_{speaker}$ and listener-only $\ell^*_{listener}$ languages that contain ambiguity. In line with Zipf's predictions, if languages are designed only to minimize speaker effort then optimal languages will assign lower-cost forms multiple meanings (all of the speaker-optimal languages contained ambiguity). Likewise, if languages are designed only to minimize listener effort then ambiguity should always be avoided (none of the listener-optimal languages contained ambiguity).\par

We explored the degree to which ambiguity improved efficiency during communication between rational, pragmatic agents. We showed that as contextual information increased, the optimal languages under our Cross-Entropy objective were more likely to have ambiguous lexical items. Importantly, we did not see this effect under alternative objectives which only emphasized speaker- or listener effort alone.\par

While our results indicate that ambiguity is an efficient property of contextualized language these simulations assumed that speaker-listener agents could always disambiguate items in context. That is, in our four conditions both agents had perfect knowledge of the relevant conditional distributions ($P(M|C)$). This assumption may be too strong for describing much of day-to-day communication -- we seldom begin a conversation with perfect knowledge of the current context of a conversation. We explore a case in which the listener has imperfect knowledge of context at the start of the conversation in Simulation 2.\par

# Simulation 2: Rational, pragmatic speakers use ambiguity efficiently

We shift time-scales in Simulation 2 -- instead of examining the objective landscape of a space of languages, we now consider a single language that contains ambiguity and examine how that property is used over a discourse. If context is not informative with respect to meaning early in a discourse (position $i$), but is at later positions at position (position $i+k$), then the speaker should avoid using ambigous material early $i$, only using it $k$ steps later in the conversation. In this toy example we can consider “context” as analogous to a “topic” of conversation. Intuitively, we can imagine a scenario in which a reader is beginning a newspaper article. While they may have some knowledge about the article’s topic (perhaps from the title), they may not have complete knowledge of its contents, including the persons or events involved. In this setting, using an ambiguous pronoun early (position $i$) in the article can lead to misunderstanding without sufficient context to support disambiguation. But if by position $i+k$ there is sufficient contextual information it may be efficient for the writer to use ambiguous material.\par

##  Simulation set-up

We consider consider a single language $\ell$, which contains both ambiguous and unambiguous utterances. The ambiguous utterances are less costly than the unambiguous utterances. Crucially, we do not assume that the listener knows the particular topic ($c_{current}$) of the conversation \textit{a priori}. Rather, we assume that the listener has knowledge of the set of possible topics $C = \{c_1, \dots, c_k\}$, but \textit{does not know which one is currently being used by the speaker}. Formally, this means the listener does not have access to the correct conditional distribution over meanings $P(M|C=c_{current})$ at the start of the discourse. In this setting, a speaker minimizing production effort would like to use the low-cost material as frequently as possible. However, this will incur a disambiguation cost to the listener if they are uncertain of the current context $c_{current}$ (topic of conversation).\par 

Over the course of a discourse, $D$ the listener tries to infer both the current topic, $c_{current}$, as well as the particular meaning $m$ of a given utterance $u$. That is, we consider updated listener and speakers ($L(m, c|u,D;\ell)$, $S(u|m,c,D;\ell)$). Note that both the speaker and listener can track the history of previous utterances $D$. Importantly, an agent can attempt to infer the current topic of conversation $c_{current}$ using the discourse history $D$ (see SI section 3 for more detail).\par

```{r plot-optimal-use, fig.env = "figure*", fig.pos = "h", fig.width=6, fig.height=2.5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "(A) shows the empirical probability that our speaker used an ambiguous utterance as a function of discourse position. (B) shows speaker effort across the three models. (C) shows the Cross-Entropy objective under our three speaker models. Error bars represent 95% confidence intervals."}

img <- png::readPNG("figs/discourse_grid_plot.png")
grid::grid.raster(img)
```

We conduct $N=600$ simulations, generating discourses of length $|D|=30$ utterances with three different speaker models ($n=200$ each). We consider a single language $\ell$\footnote{See SI for the matrix notation of this langauge.} with $|U|=6$ and $|M|=4$ in which two of the utterances $u_5$ and $u_6$ are ambiguous and that $p(u_5) = p(u_6) > p(u_{1})=\dots=p(u_{4})$. That is, the two ambiguous utterances ($u_5$ and $u_6$) are less costly than the non-ambiguous utterances. (Note that use of this particular language is not essential -- the results are broadly generalizable languages that contain ambiguity.)\par

## Speaker agents
We consider three types of speaker models. In our \textit{Full pragmatics} model, we consider a speaker agent who reasons about her listener and also has complete recall of the set of utterances in the discourse $D$. This speaker believes that the listener may not know the current topic $c_{current}$ at the start of the discrouse, but can infer it with enough data. In this way, contextual information shared by the speaker and listener may increase over the discourse (as the listeners estimate of the current topic ($P(C=c|D)$) comes in line with the actual topic known to the speaker). We compare two baselines models. The first, a \textit{Partial pragmatics} baseline describes a speaker who reasons about a listener, but assumes they have no access to discourse history. The second is a \textit{No pragmatics} speaker who does not consider a listener at all, but produces utterances according to the underlying langauge semantics ($\ell$) and topic probabilities ($p(M|C=c_{current}$) (see SI section 3 for details).\par

## Hypotheses

We assess whether it is efficient to use low-cost, ambiguous material when context is disambiguating. In the current setting, this corresponds to speaker behavior in which ambiguous forms are avoided early in the discourse, but prefered later in the discourse once the listener is confident of the topic. We should expect this to be reflected in our \textit{Full pragmatics} model. By contrast, our \textit{Partial pragmatics} speaker does not believe that there is sufficient contextual information for the listener to disambiguate her utterances. This should lead to total  avoidance of ambiguous material over the discourse. Finally, our \textit{No pragmatics} speaker should use low-cost material greedily since she does not consider a listener's need to disambiguate whatsoever.\par

## Results and Discussion

Figure 2, (A) shows the empirical probability that a speaker uses an ambiguous utterance as a function of discourse position. The \text{No pragmatic} baseline uses ambiguous utterances frequently and at a constant rate over the discourse and the \text{Partial pragmatic} baseline avoids ambiguous utterances entirely (reasoning that the utterances cannot be disambiguated). But, the \text{Full pragmatic} model avoids ambiguous material at first, but employing them gradually increasingly as the discourse proceeds. (B) shows the speaker-listener Cross-Entropy objective. Note that the objective decreases for all three models. This decrease in all three models is primarily driven by the listener updating his belief about the actual topic ($P(C=c_{current}|D)$). Of particular importance is the value of the objective at the end of the discourse (position $i=30$). The difference in the Cross-Entropy between the \text{Full Pragmatic} and \text{Partial Pragmatic} models at the end of the discourse is driven by the reduction in speaker costs described in (C). That is, while speaker effort remains constant in both \textit{No pragmatic} and \textit{Partial pragmatic} baselines, effort declines for the \text{Full Pragmatic} model as they are increasingly able to use ambiguous material later in the discourse.\par

In Simulation 2 we explored how ambiguity could be employed efficiently during discourse. We assumed that the listener did not know the current context (topic) \textit{a priori}, but could infer it from the discourse history. We examined speaker production behavior, tracking use of low-cost, but ambiguous material over the discourse. Early in the discourse the \textit{Full pragmatic} speaker avoided using ambiguous material, only using the material later when the context was known to the listener -- it is useful to use low-cost material, but only when context is disambiguating.

# General Discussion

How do the competing pressures of speakers and listeners give rise to the distributional forms found in natural language? Zipf [-@Zipf1949a] proposed that the asymmetry between speaker and listener costs gives rise to a range of properties at the level of the lexicon. We explored the interactions of rational pragmatic agents as a framework for understanding efficient language structure and use. We focused on an argument on the communicative function of ambiguity [@Piantadosi2011a]. We derive a novel speaker-listener cross-entropy objective for measuring the efficiency of a language in a reference game setting showing that optimal languages are more likely to contain ambiguous material when context is informative. Further we show that rational pragmatic agents will *use* ambiguous material efficiently, only when such use is supported by context.\par

The framework employed here -- the analysis of the dynamics of repeated reference games between rational pragmatic agents -- provides a tool for the analysis of functionalist theories, allowing linkage across timescales of analysis from conversation [@LevyJaeger2007a; @GenzelCharniak2002a] to typology [@RegierKempKay2015a]. In theory, this framework provides extensive opportunity to vary properties of the languages and agents, however we have focused on only a small subset here. For example, examining how increasing or decreasing \textit{rationality} (instantiated through the RSA $\alpha$ parameter) or \textit{pragmatics} (instantiated through the RSA recursion depth) impacts these results is a clear avenue for future work. An important limitation of the current work is the broad assumption that language can be described through such reference games. The degree to which properties of non-referential language can be captured in such a framework remains an important target for future work.

\vspace{1em} \fbox{\parbox[b][][c]{7.3cm}{\centering All simulation and analysis code are available in the public repository for the project: (link will be available upon acceptance)}} \vspace{1em}
\noindent

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
 \noindent
